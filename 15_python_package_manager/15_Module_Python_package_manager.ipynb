{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy1_hR9MlchZ"
      },
      "outputs": [],
      "source": [
        "# Module 15 - Python Package Manager Exercises\n",
        "# This cell includes imports and any setup needed.\n",
        "\n",
        "import requests\n",
        "import re\n",
        "from collections import Counter\n",
        "import json\n",
        "import math\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: Romeo and Juliet - 10 Most Frequent Words\n",
        "\n",
        "def most_frequent_words(url, num_words=10):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses\n",
        "        text = response.text.lower()\n",
        "        words = re.findall(r'\\b\\w+\\b', text)\n",
        "        word_counts = Counter(words)\n",
        "        return word_counts.most_common(num_words)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching or processing URL: {e}\")\n",
        "        return None\n",
        "\n",
        "romeo_and_juliet_url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
        "top_words = most_frequent_words(romeo_and_juliet_url)\n",
        "\n",
        "if top_words:\n",
        "    print(\"Romeo and Juliet - 10 Most Frequent Words:\")\n",
        "    for word, count in top_words:\n",
        "        print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "id": "w7IfotHWldlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2: Cats API - Weight and Lifespan Stats\n",
        "\n",
        "def calculate_stats(data, key):\n",
        "    values = [float(item[key]) for item in data if item[key] is not None and item[key] != 'NaN']\n",
        "    if not values:\n",
        "      return None, None, None, None, None\n",
        "\n",
        "    min_val = min(values)\n",
        "    max_val = max(values)\n",
        "    mean_val = sum(values) / len(values)\n",
        "    sorted_values = sorted(values)\n",
        "    mid = len(sorted_values) // 2\n",
        "    median_val = (sorted_values[mid - 1] + sorted_values[mid]) / 2 if len(sorted_values) % 2 == 0 else sorted_values[mid]\n",
        "    variance = sum((x - mean_val) ** 2 for x in values) / len(values)\n",
        "    std_val = math.sqrt(variance)\n",
        "    return min_val, max_val, mean_val, median_val, std_val\n",
        "\n",
        "\n",
        "def cats_stats(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        weights = []\n",
        "        lifespans = []\n",
        "        for cat in data:\n",
        "          if 'weight' in cat and 'metric' in cat['weight']:\n",
        "            try:\n",
        "              weights.append(float(cat['weight']['metric'].split(\" - \")[0]))#some are formatted as \"x - y\"\n",
        "            except:\n",
        "              pass #ignore if not able to process.\n",
        "          if 'life_span' in cat:\n",
        "            try:\n",
        "              lifespans.append(float(cat['life_span'].split(\" - \")[0]))#some are formatted as \"x - y\"\n",
        "            except:\n",
        "              pass #ignore if not able to process.\n",
        "\n",
        "        weight_stats = calculate_stats(data, 'metric')\n",
        "        lifespan_stats = calculate_stats(data, 'life_span')\n",
        "\n",
        "        if weight_stats[0] is not None:\n",
        "          print(\"\\nCat Weights (Metric):\")\n",
        "          print(f\"  Min: {weight_stats[0]:.2f}\")\n",
        "          print(f\"  Max: {weight_stats[1]:.2f}\")\n",
        "          print(f\"  Mean: {weight_stats[2]:.2f}\")\n",
        "          print(f\"  Median: {weight_stats[3]:.2f}\")\n",
        "          print(f\"  Std Dev: {weight_stats[4]:.2f}\")\n",
        "\n",
        "        if lifespan_stats[0] is not None:\n",
        "          print(\"\\nCat Lifespans (Years):\")\n",
        "          print(f\"  Min: {lifespan_stats[0]:.2f}\")\n",
        "          print(f\"  Max: {lifespan_stats[1]:.2f}\")\n",
        "          print(f\"  Mean: {lifespan_stats[2]:.2f}\")\n",
        "          print(f\"  Median: {lifespan_stats[3]:.2f}\")\n",
        "          print(f\"  Std Dev: {lifespan_stats[4]:.2f}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching or processing Cat API: {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing: {e}\")\n",
        "\n",
        "\n",
        "cats_api_url = 'https://api.thecatapi.com/v1/breeds'\n",
        "cats_stats(cats_api_url)"
      ],
      "metadata": {
        "id": "tBgiSYyhldiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: Cats API - Frequency Table of Country and Breed\n",
        "\n",
        "def create_frequency_table(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        freq_table = {}\n",
        "        for cat in data:\n",
        "            country = cat.get('origin', 'Unknown')\n",
        "            breed = cat.get('name', 'Unknown')\n",
        "\n",
        "            if country in freq_table:\n",
        "              if breed in freq_table[country]:\n",
        "                freq_table[country][breed] += 1\n",
        "              else:\n",
        "                freq_table[country][breed] = 1\n",
        "            else:\n",
        "              freq_table[country] = {breed: 1}\n",
        "\n",
        "\n",
        "        print(\"\\nCat Country and Breed Frequency Table:\")\n",
        "        for country, breeds in freq_table.items():\n",
        "            print(f\"  {country}:\")\n",
        "            for breed, count in breeds.items():\n",
        "                print(f\"    - {breed}: {count}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "         print(f\"Error fetching or processing Cat API: {e}\")\n",
        "\n",
        "\n",
        "cats_api_url = 'https://api.thecatapi.com/v1/breeds'\n",
        "create_frequency_table(cats_api_url)"
      ],
      "metadata": {
        "id": "ro41ws2Al7sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: Countries API - Largest Countries and Languages\n",
        "def country_stats(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        countries = response.json()\n",
        "\n",
        "        # 10 Largest Countries\n",
        "        sorted_countries = sorted(countries, key=lambda country: country.get('area', 0), reverse=True)[:10]\n",
        "        print(\"\\n10 Largest Countries:\")\n",
        "        for country in sorted_countries:\n",
        "            print(f\"  {country['name']['common']}: {country.get('area', 'N/A')} sq km\")\n",
        "\n",
        "        # 10 Most Spoken Languages\n",
        "        language_counts = {}\n",
        "        for country in countries:\n",
        "            if 'languages' in country:\n",
        "              for language in country['languages'].values():\n",
        "                  language_counts[language] = language_counts.get(language, 0) + 1\n",
        "\n",
        "        sorted_languages = sorted(language_counts.items(), key=lambda item: item[1], reverse=True)[:10]\n",
        "        print(\"\\n10 Most Spoken Languages:\")\n",
        "        for language, count in sorted_languages:\n",
        "            print(f\"  {language}: {count}\")\n",
        "\n",
        "        # Total Number of Languages\n",
        "        total_languages = sum(len(country.get('languages', {})) for country in countries)\n",
        "        print(f\"\\nTotal Number of Languages: {total_languages}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching or processing Countries API: {e}\")\n",
        "\n",
        "countries_api_url = 'https://restcountries.com/v3.1/all'\n",
        "country_stats(countries_api_url)"
      ],
      "metadata": {
        "id": "fiI_yzgEldfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 5: UCI Datasets - Web Scraping\n",
        "\n",
        "def fetch_uci_datasets(url):\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    table = soup.find('table', {'border':'1', 'cellpadding':'3'})\n",
        "    if table:\n",
        "       rows = table.find_all('tr')\n",
        "       for row in rows[1:]:\n",
        "        cells = row.find_all('td')\n",
        "        if len(cells) >= 2:\n",
        "          print(f\"dataset: {cells[1].text}\")\n",
        "    else:\n",
        "        print(\"No table was found with those attributes.\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching UCL page: {e}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error has occurred: {e}\")\n",
        "\n",
        "\n",
        "uci_url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
        "fetch_uci_datasets(uci_url)"
      ],
      "metadata": {
        "id": "qyETrulQmB4h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}